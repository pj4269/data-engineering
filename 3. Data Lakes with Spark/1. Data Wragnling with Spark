- functional programming (no globals, OOP)
- immutable

- Maps and La,mbda => most common functions.

import pyspark
sc = pyspark.SparkContext(appName="maps_and_lazy_evaluation_example")

log_of_songs = [ "Despacito", "Nice for what", "No tears left to cry", "Despacito", "Havana", "In my feelings", "Nice for what", "despacito", "All the stars" ]

# parallelize the log_of_songs to use with Spark
distributed_song_log = sc.parallelize(log_of_songs)

def convert_song_to_lowercase(song):
    return song.lower()
# maps and lambda are same in the below
                                                   # action
distributed_song_log.map(convert_song_to_lowercase).collect()

distributed_song_log.map(lambda x: x.lower()).collect()
